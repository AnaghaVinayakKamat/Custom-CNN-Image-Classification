{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3d89683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.70980394, 0.827451  , 0.93333334],\n",
       "         [0.7254902 , 0.84313726, 0.9490196 ],\n",
       "         [0.7647059 , 0.85882354, 0.95686275],\n",
       "         ...,\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.9647059 , 0.9882353 , 0.9882353 ]],\n",
       "\n",
       "        [[0.7411765 , 0.8352941 , 0.93333334],\n",
       "         [0.7607843 , 0.8666667 , 0.95686275],\n",
       "         [0.78431374, 0.8745098 , 0.96862745],\n",
       "         ...,\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.9843137 , 0.99607843, 0.99215686]],\n",
       "\n",
       "        [[0.7607843 , 0.8627451 , 0.94509804],\n",
       "         [0.78431374, 0.88235295, 0.9607843 ],\n",
       "         [0.8039216 , 0.8862745 , 0.96862745],\n",
       "         ...,\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99607843, 0.99607843, 0.99607843]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.3647059 , 0.32941177, 0.27058825],\n",
       "         [0.32941177, 0.29411766, 0.2627451 ],\n",
       "         [0.34509805, 0.29411766, 0.23529412],\n",
       "         ...,\n",
       "         [0.40392157, 0.38039216, 0.30980393],\n",
       "         [0.28235295, 0.26666668, 0.22745098],\n",
       "         [0.34117648, 0.29803923, 0.25490198]],\n",
       "\n",
       "        [[0.06666667, 0.07450981, 0.07058824],\n",
       "         [0.2901961 , 0.2901961 , 0.23529412],\n",
       "         [0.21568628, 0.22745098, 0.18431373],\n",
       "         ...,\n",
       "         [0.34509805, 0.3137255 , 0.26666668],\n",
       "         [0.30980393, 0.2901961 , 0.24705882],\n",
       "         [0.24313726, 0.21568628, 0.18039216]],\n",
       "\n",
       "        [[0.18431373, 0.1882353 , 0.13333334],\n",
       "         [0.34509805, 0.32156864, 0.25490198],\n",
       "         [0.34509805, 0.3254902 , 0.26666668],\n",
       "         ...,\n",
       "         [0.26666668, 0.2627451 , 0.22352941],\n",
       "         [0.32156864, 0.29411766, 0.24313726],\n",
       "         [0.26666668, 0.2509804 , 0.21960784]]],\n",
       "\n",
       "\n",
       "       [[[0.42352942, 0.56078434, 0.32156864],\n",
       "         [0.3882353 , 0.5019608 , 0.2784314 ],\n",
       "         [0.45882353, 0.5568628 , 0.34117648],\n",
       "         ...,\n",
       "         [0.5137255 , 0.49019608, 0.44705883],\n",
       "         [0.81960785, 0.77254903, 0.7294118 ],\n",
       "         [0.69803923, 0.6745098 , 0.6431373 ]],\n",
       "\n",
       "        [[0.46666667, 0.5882353 , 0.32156864],\n",
       "         [0.44313726, 0.5686275 , 0.30980393],\n",
       "         [0.47058824, 0.5882353 , 0.3372549 ],\n",
       "         ...,\n",
       "         [0.47058824, 0.41960785, 0.4       ],\n",
       "         [0.49019608, 0.42745098, 0.31764707],\n",
       "         [0.5647059 , 0.49019608, 0.41568628]],\n",
       "\n",
       "        [[0.46666667, 0.5764706 , 0.33333334],\n",
       "         [0.48235294, 0.62352943, 0.38431373],\n",
       "         [0.45490196, 0.6039216 , 0.3647059 ],\n",
       "         ...,\n",
       "         [0.49019608, 0.42745098, 0.36078432],\n",
       "         [0.68235296, 0.5803922 , 0.46666667],\n",
       "         [0.65882355, 0.5686275 , 0.43529412]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.6627451 , 0.6       , 0.54509807],\n",
       "         [0.7647059 , 0.70980394, 0.63529414],\n",
       "         [0.6666667 , 0.62352943, 0.5254902 ],\n",
       "         ...,\n",
       "         [0.6901961 , 0.6313726 , 0.6156863 ],\n",
       "         [0.7411765 , 0.68235296, 0.64705884],\n",
       "         [0.7372549 , 0.65882355, 0.56078434]],\n",
       "\n",
       "        [[0.47843137, 0.40784314, 0.31764707],\n",
       "         [0.627451  , 0.654902  , 0.5529412 ],\n",
       "         [0.5019608 , 0.46666667, 0.27058825],\n",
       "         ...,\n",
       "         [0.52156866, 0.41960785, 0.38431373],\n",
       "         [0.7647059 , 0.69803923, 0.654902  ],\n",
       "         [0.5019608 , 0.44705883, 0.44313726]],\n",
       "\n",
       "        [[0.59607846, 0.6       , 0.45882353],\n",
       "         [0.60784316, 0.627451  , 0.48235294],\n",
       "         [0.4745098 , 0.5568628 , 0.33333334],\n",
       "         ...,\n",
       "         [0.7411765 , 0.6862745 , 0.64705884],\n",
       "         [0.73333335, 0.7137255 , 0.7019608 ],\n",
       "         [0.7607843 , 0.7529412 , 0.70980394]]],\n",
       "\n",
       "\n",
       "       [[[0.69411767, 0.654902  , 0.60784316],\n",
       "         [0.49019608, 0.38039216, 0.36862746],\n",
       "         [0.19607843, 0.24705882, 0.22352941],\n",
       "         ...,\n",
       "         [0.13725491, 0.21960784, 0.03921569],\n",
       "         [0.25882354, 0.39607844, 0.29411766],\n",
       "         [0.27450982, 0.40392157, 0.3137255 ]],\n",
       "\n",
       "        [[0.58431375, 0.5058824 , 0.47058824],\n",
       "         [0.5058824 , 0.43529412, 0.35686275],\n",
       "         [0.2       , 0.23529412, 0.27058825],\n",
       "         ...,\n",
       "         [0.09411765, 0.16078432, 0.10588235],\n",
       "         [0.34901962, 0.43529412, 0.34901962],\n",
       "         [0.26666668, 0.43529412, 0.34509805]],\n",
       "\n",
       "        [[0.6156863 , 0.50980395, 0.46666667],\n",
       "         [0.16470589, 0.2627451 , 0.12156863],\n",
       "         [0.18431373, 0.21960784, 0.22352941],\n",
       "         ...,\n",
       "         [0.52156866, 0.7294118 , 0.5647059 ],\n",
       "         [0.4       , 0.6039216 , 0.4509804 ],\n",
       "         [0.26666668, 0.46666667, 0.33333334]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.5137255 , 0.67058825, 0.62352943],\n",
       "         [0.23921569, 0.21960784, 0.15686275],\n",
       "         [0.13333334, 0.15294118, 0.12156863],\n",
       "         ...,\n",
       "         [0.21568628, 0.36078432, 0.22352941],\n",
       "         [0.11372549, 0.28627452, 0.16470589],\n",
       "         [0.09019608, 0.20784314, 0.08235294]],\n",
       "\n",
       "        [[0.34117648, 0.49803922, 0.3882353 ],\n",
       "         [0.16078432, 0.29803923, 0.13333334],\n",
       "         [0.07058824, 0.11372549, 0.07843138],\n",
       "         ...,\n",
       "         [0.07450981, 0.07843138, 0.03921569],\n",
       "         [0.07843138, 0.17254902, 0.06666667],\n",
       "         [0.01568628, 0.03921569, 0.03137255]],\n",
       "\n",
       "        [[0.1764706 , 0.3137255 , 0.16470589],\n",
       "         [0.09803922, 0.19215687, 0.09803922],\n",
       "         [0.05098039, 0.07058824, 0.03137255],\n",
       "         ...,\n",
       "         [0.06666667, 0.05882353, 0.03529412],\n",
       "         [0.06666667, 0.14117648, 0.03921569],\n",
       "         [0.03921569, 0.03921569, 0.02745098]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.6666667 , 0.62352943, 0.56078434],\n",
       "         [0.75686276, 0.7019608 , 0.6509804 ],\n",
       "         [0.5921569 , 0.54901963, 0.5058824 ],\n",
       "         ...,\n",
       "         [0.41568628, 0.4117647 , 0.39215687],\n",
       "         [0.44705883, 0.4117647 , 0.3764706 ],\n",
       "         [0.3764706 , 0.3647059 , 0.36862746]],\n",
       "\n",
       "        [[0.60784316, 0.5803922 , 0.5019608 ],\n",
       "         [0.7137255 , 0.7058824 , 0.6       ],\n",
       "         [0.41960785, 0.47058824, 0.3529412 ],\n",
       "         ...,\n",
       "         [0.52156866, 0.5686275 , 0.5137255 ],\n",
       "         [0.47058824, 0.44313726, 0.3882353 ],\n",
       "         [0.32941177, 0.33333334, 0.28627452]],\n",
       "\n",
       "        [[0.44705883, 0.42352942, 0.4       ],\n",
       "         [0.6745098 , 0.6431373 , 0.5686275 ],\n",
       "         [0.5294118 , 0.52156866, 0.42745098],\n",
       "         ...,\n",
       "         [0.6039216 , 0.64705884, 0.5882353 ],\n",
       "         [0.68235296, 0.6117647 , 0.5294118 ],\n",
       "         [0.88235295, 0.827451  , 0.76862746]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.4509804 , 0.4117647 , 0.4       ],\n",
       "         [0.29411766, 0.27058825, 0.25490198],\n",
       "         [0.4392157 , 0.3764706 , 0.32941177],\n",
       "         ...,\n",
       "         [0.49411765, 0.42745098, 0.36078432],\n",
       "         [0.39215687, 0.3647059 , 0.3019608 ],\n",
       "         [0.54509807, 0.5176471 , 0.45882353]],\n",
       "\n",
       "        [[0.4627451 , 0.44313726, 0.4509804 ],\n",
       "         [0.29411766, 0.25490198, 0.23137255],\n",
       "         [0.50980395, 0.46666667, 0.44313726],\n",
       "         ...,\n",
       "         [0.38039216, 0.30588236, 0.23529412],\n",
       "         [0.46666667, 0.41568628, 0.3529412 ],\n",
       "         [0.4       , 0.3647059 , 0.32156864]],\n",
       "\n",
       "        [[0.4392157 , 0.41960785, 0.43137255],\n",
       "         [0.42352942, 0.4       , 0.40784314],\n",
       "         [0.41960785, 0.40784314, 0.41568628],\n",
       "         ...,\n",
       "         [0.24313726, 0.21176471, 0.14901961],\n",
       "         [0.48235294, 0.43137255, 0.3764706 ],\n",
       "         [0.39607844, 0.34509805, 0.29411766]]],\n",
       "\n",
       "\n",
       "       [[[0.13725491, 0.14509805, 0.21960784],\n",
       "         [0.11372549, 0.18431373, 0.18431373],\n",
       "         [0.09411765, 0.11372549, 0.17254902],\n",
       "         ...,\n",
       "         [0.12941177, 0.12156863, 0.19215687],\n",
       "         [0.49019608, 0.5882353 , 0.60784316],\n",
       "         [0.35686275, 0.43137255, 0.5058824 ]],\n",
       "\n",
       "        [[0.16862746, 0.1254902 , 0.16470589],\n",
       "         [0.09019608, 0.13333334, 0.17254902],\n",
       "         [0.14509805, 0.10196079, 0.18039216],\n",
       "         ...,\n",
       "         [0.09019608, 0.08627451, 0.15294118],\n",
       "         [0.10588235, 0.07450981, 0.1254902 ],\n",
       "         [0.1254902 , 0.08235294, 0.16862746]],\n",
       "\n",
       "        [[0.09019608, 0.14509805, 0.15686275],\n",
       "         [0.09803922, 0.1254902 , 0.18039216],\n",
       "         [0.05882353, 0.14901961, 0.14117648],\n",
       "         ...,\n",
       "         [0.12156863, 0.06666667, 0.12941177],\n",
       "         [0.09803922, 0.12941177, 0.13333334],\n",
       "         [0.08627451, 0.12941177, 0.16078432]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.8509804 , 0.9098039 , 0.9254902 ],\n",
       "         [0.7254902 , 0.7490196 , 0.7921569 ],\n",
       "         [0.7882353 , 0.8235294 , 0.84705883],\n",
       "         ...,\n",
       "         [0.58431375, 0.6       , 0.58431375],\n",
       "         [0.5686275 , 0.6039216 , 0.5529412 ],\n",
       "         [0.4862745 , 0.654902  , 0.4627451 ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [0.91764706, 0.91764706, 0.91764706],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [0.9137255 , 0.9137255 , 0.9137255 ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [0.972549  , 0.972549  , 0.972549  ],\n",
       "         [1.        , 1.        , 1.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.20784314, 0.34117648, 0.4745098 ],\n",
       "         [0.21568628, 0.37254903, 0.48235294],\n",
       "         [0.19215687, 0.34509805, 0.44705883],\n",
       "         ...,\n",
       "         [0.2       , 0.35686275, 0.4862745 ],\n",
       "         [0.21568628, 0.3764706 , 0.5137255 ],\n",
       "         [0.20392157, 0.36078432, 0.48235294]],\n",
       "\n",
       "        [[0.1764706 , 0.3254902 , 0.44705883],\n",
       "         [0.27450982, 0.41568628, 0.4745098 ],\n",
       "         [0.34509805, 0.47058824, 0.5058824 ],\n",
       "         ...,\n",
       "         [0.21176471, 0.3647059 , 0.49019608],\n",
       "         [0.18431373, 0.34509805, 0.48235294],\n",
       "         [0.22352941, 0.36078432, 0.49019608]],\n",
       "\n",
       "        [[0.2627451 , 0.35686275, 0.4627451 ],\n",
       "         [0.14901961, 0.29803923, 0.42745098],\n",
       "         [0.2784314 , 0.3882353 , 0.45882353],\n",
       "         ...,\n",
       "         [0.21568628, 0.36078432, 0.49803922],\n",
       "         [0.2509804 , 0.39607844, 0.53333336],\n",
       "         [0.2       , 0.34509805, 0.48235294]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.7647059 , 0.64705884, 0.40784314],\n",
       "         [0.6901961 , 0.63529414, 0.39607844],\n",
       "         [0.50980395, 0.49803922, 0.33333334],\n",
       "         ...,\n",
       "         [0.5568628 , 0.5294118 , 0.2627451 ],\n",
       "         [0.6156863 , 0.60784316, 0.30588236],\n",
       "         [0.4862745 , 0.5176471 , 0.28627452]],\n",
       "\n",
       "        [[0.6392157 , 0.64705884, 0.34509805],\n",
       "         [0.8156863 , 0.7921569 , 0.59607846],\n",
       "         [0.5882353 , 0.5529412 , 0.3019608 ],\n",
       "         ...,\n",
       "         [0.3647059 , 0.3254902 , 0.08235294],\n",
       "         [0.5372549 , 0.5882353 , 0.28627452],\n",
       "         [0.19215687, 0.20392157, 0.02352941]],\n",
       "\n",
       "        [[0.72156864, 0.78039217, 0.5803922 ],\n",
       "         [0.7764706 , 0.7372549 , 0.6       ],\n",
       "         [0.4745098 , 0.4117647 , 0.2627451 ],\n",
       "         ...,\n",
       "         [0.6784314 , 0.7254902 , 0.4862745 ],\n",
       "         [0.5921569 , 0.65882355, 0.27450982],\n",
       "         [0.52156866, 0.5019608 , 0.21960784]]]], dtype=float32)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "\n",
    "# Step 1: Load and preprocess image data\n",
    "\n",
    "input1 = 'alpaca/'\n",
    "filename1 = []\n",
    "for filename in os.listdir(input1):\n",
    "    filename1.append(input1 + filename)\n",
    "\n",
    "input2 = 'not alpaca/'\n",
    "filename2 = []\n",
    "for filename in os.listdir(input2):\n",
    "    filename2.append(input2 + filename)\n",
    "\n",
    "# Load and preprocess images\n",
    "def load_and_preprocess_image(filename):\n",
    "    image = cv2.imread(filename)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert from BGR to RGB\n",
    "    image = cv2.resize(image, (32, 32))  # Resize to 32x32\n",
    "    image = image.astype('float32') / 255.0  # Normalize to [0, 1]\n",
    "    return image\n",
    "\n",
    "X1 = np.array([load_and_preprocess_image(filename) for filename in filename1])\n",
    "Y1 = np.ones(len(X1), dtype=np.int32)\n",
    "\n",
    "X2 = np.array([load_and_preprocess_image(filename) for filename in filename2])\n",
    "Y2 = np.zeros(len(X2), dtype=np.int32)\n",
    "\n",
    "# Concatenate and split data\n",
    "X = np.concatenate((X1, X2), axis=0)\n",
    "Y = np.concatenate((Y1, Y2), axis=0)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.30, random_state=42)\n",
    "X_test, X_val, Y_test, Y_val = train_test_split(X_test, Y_test, test_size=0.50, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93d1c790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228, 32, 32, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a898cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class ConvolutionalLayer(nn.Module):\n",
    "    def __init__(self, input_size, num_channels, filter_size):\n",
    "        super(ConvolutionalLayer, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.num_channels = num_channels\n",
    "        self.filter_size = filter_size\n",
    "        #make weights matrix the same size as the input\n",
    "        self.weight_matrix = nn.Parameter(torch.randn(batch_size, num_channels, input_size[0], input_size[1]))\n",
    "        self.output_size = (input_size[0] - filter_size[0] + 1, input_size[1] - filter_size[1] + 1)\n",
    "        self.output_feature_map = torch.zeros((self.num_channels, self.output_size[0], self.output_size[1]))\n",
    "\n",
    "    def forward(self, input_feature_map):\n",
    "        batch_size = input_feature_map.size(0)\n",
    "        output_feature_maps = []\n",
    "        for i in range(batch_size):\n",
    "            output_feature_map = torch.zeros((self.num_channels, self.output_size[0], self.output_size[1]))\n",
    "            for k in range(self.num_channels):\n",
    "                for j in range(self.output_size[0]):\n",
    "                    for l in range(self.output_size[1]):\n",
    "                        #the same receptive field is applied to the weights as the input\n",
    "                        receptive_field = input_feature_map[i, :, j:j+self.filter_size[0], l:l+self.filter_size[1]]\n",
    "                        receptive_field_weight = self.weight_matrix[i, :, j:j+self.filter_size[0], l:l+self.filter_size[1]]\n",
    "                        weighted_output = torch.sum(receptive_field * receptive_field_weight, dim=(1,2))\n",
    "                        output_feature_map[k, j, l] = weighted_output[k]\n",
    "            output_feature_maps.append(output_feature_map)\n",
    "        output_feature_maps = torch.stack(output_feature_maps, dim=0)\n",
    "        return output_feature_maps\n",
    "    \n",
    "    def backward(self, grad_output):\n",
    "        batch_size = grad_output.size(0)\n",
    "        grad_input = torch.zeros((batch_size, self.input_size[0], self.input_size[1], self.filter_size[0], self.filter_size[1]), device=self.weight_matrix.device)\n",
    "        grad_weight = torch.zeros_like(self.weight_matrix)\n",
    "        for i in range(batch_size):\n",
    "            for k in range(self.num_channels):\n",
    "                for j in range(self.output_size[0]):\n",
    "                    for l in range(self.output_size[1]):\n",
    "                        # compute the gradient of the output w.r.t. the receptive field\n",
    "                        grad_weight[k] += grad_output[i, k, j, l] * self.input_feature_map[i, :, j:j+self.filter_size[0], l:l+self.filter_size[1]]\n",
    "                        # compute the gradient of the output w.r.t. the input feature map\n",
    "                        grad_input[i, :, j:j+self.filter_size[0], l:l+self.filter_size[1]] += grad_output[i, k, j, l] * self.weight_matrix[k]\n",
    "        self.weight_matrix.grad = torch.sum(grad_weight, dim=0, keepdim=True)\n",
    "        return grad_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b54e7392",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5864\\109424073.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0moutput_feature_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_feature_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Print the shapes of the input and output feature maps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5864\\742674565.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_feature_map)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_feature_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_feature_map\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0moutput_feature_maps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "    \n",
    "batch_size = 2\n",
    "num_channels = 3\n",
    "input_size = (4, 4)\n",
    "#input_feature_map = torch.randn(batch_size, num_channels, input_size[0], input_size[1])\n",
    "input_feature_map = X_train\n",
    "\n",
    "# Create a ConvolutionalLayer instance\n",
    "conv_layer = ConvolutionalLayer(input_size, num_channels, filter_size=(3, 3))\n",
    "\n",
    "# Forward pass\n",
    "output_feature_map = conv_layer(input_feature_map)\n",
    "\n",
    "# Print the shapes of the input and output feature maps\n",
    "print(\"Input feature map shape:\", input_feature_map.shape)\n",
    "print(\"Output feature map shape:\", output_feature_map.shape)\n",
    "output_feature_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcaf277",
   "metadata": {},
   "source": [
    "Now try on X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8388cb72",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5864\\521929389.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0moutput_feature_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_feature_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Print the shapes of the input and output feature maps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5864\\742674565.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_feature_map)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_feature_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_feature_map\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0moutput_feature_maps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 2\n",
    "num_channels = 3\n",
    "input_size = (32,32)\n",
    "#input_feature_map = torch.randn(batch_size, num_channels, input_size[0], input_size[1])\n",
    "input_feature_map = X_train\n",
    "\n",
    "# Create a ConvolutionalLayer instance\n",
    "conv_layer = ConvolutionalLayer(input_size, num_channels, filter_size=(3, 3))\n",
    "\n",
    "# Forward pass\n",
    "output_feature_map = conv_layer(input_feature_map)\n",
    "\n",
    "# Print the shapes of the input and output feature maps\n",
    "print(\"Input feature map shape:\", input_feature_map.shape)\n",
    "print(\"Output feature map shape:\", output_feature_map.shape)\n",
    "output_feature_map"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
